**Gaunt Sloth - code reviews without AI provider lock-ins and without subscription**

This is my first Substack post, so here’s the quick catch-up: in 2024 I cobbled together a few JS scripts that ran AI code reviews for me, and the workflow worked so well that by April 2025 I published Gaunt Sloth 0.0.1 to npm. The tool is a TypeScript/LangChain CLI that runs on Linux, macOS, and Windows, pipes diffs straight into LLMs, and lets you craft your own system prompts. The idea was simple — give developers a fast, configurable AI helper they could install with `npm install -g gaunt-sloth-assistant` and bend to their workflow without waiting for somebody else’s SaaS roadmap. Today are finally at 1.0.0, have more than 70 releases on NPM and almost 800 commits in main.

## Core Capabilities Today

Gaunt Sloth is an Open Source project and was built to avoid lock-ins, especially around code reviews. Everything runs locally or in your CI, every prompt lives in your repo, and every model call goes through your own API keys. In practice that translates to:

- **Source-agnostic reviews.** Pipe Git diffs via stdin, point at local files, or let the CLI pull GitHub PRs and stitch in Jira/GitHub requirements automatically (as easy as `gth pr 42 JR-12`).
- **Prompt and persona control.** Identity profiles let you ship multiple `.gsloth/.gsloth-settings/<profile>` folders, so switching from a “strict reviewer” prompt to a “DevOps helper” is just a `-i profile` flag.
- **Filesystem-aware sessions.** `gth code` opens an interactive coding loop with read/write access, while `gth chat` gives you a structured chat using the same configs and middleware stack. I'm using code/chat sessions to talk to remote Atlassian MCP to do stuff in Jira and Confluence for me (some configs and prompts specific for your project needed).
- **Tooling without AI provider lock-in.** Bring in MCP servers (Jira, custom backends), local LangChain tools, or even Ollama models. If LangChain speaks to it, Gaunt Sloth does too.
- **CI-friendly outputs.** Automated ratings, `setExitCode`, and configurable output files make it trivial to wire into GitHub Actions, Jenkins, or any pipeline that just needs a process exit code and a summary artifact.

https://github.com/Galvanized-Pukeko/gaunt-sloth-assistant

https://www.npmjs.com/package/gaunt-sloth-assistant

`npm install -g gaunt-sloth-assistant`

## From First Commit to 1.0.0

At 0.0.3 the CLI already reviewed pull requests and matched them with Jira or GitHub requirements, read local diffs (`git --no-pager diff | gth review`), soon by the version 0.1.0 we added a feature pulling Jira issue to check the diff against requirements from the issue description, soon `gth chat` and `gth code` were added.

By the end of July the project hit version 0.9.7. A couple of new contributors landed, we crossed 500 commits, and we proved Gaunt Sloth could run inside GitHub Actions via the published `.github/workflows/review.yml` (with the usual API-key caveats for public PRs). The CLI learned how to run tests and lint on demand, so you could ask it to build an entire feature end-to-end and watch it execute your scripts - Gaunt Sloth is not as capable as claude-code or codex, but sometimes it could do for coding as well. The chat loop got sturdier thanks to retries for “model overloaded” moments, presets arrived for OpenRouter, and we confirmed that certain Ollama text-generation models worked just fine. Documentation was still mostly two markdowns, but Typedoc-backed docs were on the roadmap.

Around the same time I wired Gaunt Sloth into a GitHub Actions workflow for another project and discovered the nice side effect: cost control. Most SaaS review bots want per-developer seats, which adds up fast and forces everyone to use the same assistant. Running Gaunt Sloth in CI means we maintain a single API key, pay only for the tokens the action consumes, and let teammates keep whatever tooling they prefer locally. Because every prompt lives in the repo, we can tune it to our standards and swap in any LangChain-supported model — from provider-hosted LLMs to an Ollama instance — without renegotiating a subscription.

Fast forward to now and the 1.0.0 release. We bumped the runtime baseline to Node 24/npm 11, upgraded LangChain/LangGraph to v1, and added the architecture we wanted from day one:

- **Review ratings everywhere.** Every `review` or `pr` run now ends with a numerical score and comment, stored in an artifact shared with the review module. The new rater tool plugs into `setExitCode`, so CI can fail automatically when the score dips below the threshold you configure (and you can still disable it via `commands.<cmd>.rating.enabled = false` if you only want warnings).
- **Identity profiles.** `gth -i devops pr 555 PP-4242` loads prompts, models, and providers from `.gsloth/.gsloth-settings/devops/`, so you can keep separate personas for DevOps, documentation, or even a Jira MCP profile with its own OAuth credentials and transport settings.
- **First-class middleware.** Built-ins like `anthropic-prompt-caching` or `summarization` now live in a registry, display alongside loaded tools, and you can drop in your own JS middleware objects to wrap model or tool calls.
- **Better configs, sturdier plumbing.** Command configs now deep-merge, OAuth caching is less annoying, docs and README were refreshed, dependencies hardened, and `writeOutputToFile` plus `setExitCode` got the polish they deserved.

Under the hood there’s now an in-memory artifact store so middleware and modules can share structured data, which makes future automation easier. The CLI is still a small TypeScript binary you can install globally or run via `npx gth`, but the internals are clean enough to evolve without hacks—whether that means new MCP integrations, richer review heuristics, or completely different personas.

If you’re curious, the fastest way to try it remains `npm install -g gaunt-sloth-assistant`. The GitHub repo (https://github.com/Galvanized-Pukeko/gaunt-sloth-assistant) tracks issues, discussions, and release notes. File a bug, ask for a preset, or point the new rater at your CI and tell me how it behaves — I’m building 1.1 plans right now.

Thanks to everyone who tested builds or sent the handful of PRs that nudged the project forward. Substack felt like the right place to share this journey, so more Gaunt Sloth stories are on the way.
